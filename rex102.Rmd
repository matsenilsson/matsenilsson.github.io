---
title: False
author: "Mats E. Nilsson"
---

```{r setup, cache = FALSE, echo = FALSE}
# THis will allow error messages to be converted to HTML
knitr::opts_chunk$set(error = TRUE)
```
\  
\


# Notes REX102
Today a bit about missing data and how to deal with them. Then a few examples of 
the powerful plotting tools available for data screening in R. And then we will
continue our work on Script 2: An analysis of data from a listening experiment.

\  

### Missing data
As you know, missing data in R is coded `NA`. However, many data sets contain 
other error codes, like 999. Some data sets include several error codes, for 
example 99 for a missing questionnaire response and 999 for an incorrect response
(e.g., if two boxes were ticked when only one was allowed). Make sure you don't
analyse these error codes as real data. And make sure no one do the same with your 
data: document clearly how you coded missing data in the file (code book)
explaining your data set.

Here I create some fake data, with values = 999 representing missing data. Mean 
values of each variable should be around 0, but are much higher for some thanks 
to error codes handled as real data. This is easily spotted using the function 
`summary`. Note the use of `sapply` to calculate things for each column of the
data frame.
```{r }
set.seed(123)
x <- rnorm(1000)
miss <- sample(1000, 7)
x[miss] <- 999
d <- data.frame(matrix(x, nrow = 100, ncol = 10))
summary(d[1:3])  # Just first three columns to illustrate 
sum(d == 999)  # Total number of missing values coded 999
sapply(d, max) # Maximum value of each variable. 
sapply(d, function(x) sum(x == 999)) # How many 999's per variable?  
```

### Recoding missing
How to recode the 999's to NA? Below is an expert's trick that I learnt from reading
Hadley Wickhams book [Advanced R](http://adv-r.had.co.nz/). 

Before reading that book, I might have tried something like:
`d$X1[d$X1 == 999] <- NA`, and then copy-paste and modifying this line for each of
the ten variables in `d`. Would work for this small data set, but what if I had 
139 variables: A lot of time and an accumulated risk for introducing errors.  

This is much more efficient and safer:
```{r }
recode_missing <- function(x) {
  # Takes a vector as input, and recodes any instance of 999 to NA;
  # outputs the recoded vector
  x[x == 999] <- NA
  x
}

# Use lapply() to recode. d[] keepd d as a data frame (lapply() wants to return a list)
d[] <- lapply(d, recode_missing)  
sapply(d, function(x) sum(x == 999, na.rm = TRUE)) # How many 999's per variable? 
sapply(d, function(x) sum(is.na(x))) # How many NA's per variable?
```

If your data frame contains vectors of different types, for example some numeric 
and some characters (with missing coded '999' rather than 999), you may need to 
do the recoding separately for each type of vector (or make the function 
`recode_missing` more advanced to handle different types of input). If you have 
imported data with characters, R may have turned character vectors into factors 
without asking and you may need to replace factor levels of 999 with NA's. 

\  

### Some basic plots for exploring data

I will use data from Howell's table 2.1 on reaction time (RT) to illustrate how 
R's powerful plotting capabilities may be used to explore a variable. You may 
download the data here: <a href="howell_table_2_1.txt" target="_blank"
>Howell Table 2.1</a>.  
Reference: Howell, D.C. (2012). _Statistical Methods for Psychology_ 
(8th International ed.). Hampshire, UK: Wadsworth.

The RT data is from one participant (D.C. Howell). The task was to 
decide as quickly as possible whether a target number (e.g., 5) had been presented 
in a reference series of numbers (e.g., 1 6 4 3) presented just before the target was 
shown on the screen. Here we will check the full set of RT's, and also compare the 
stimuli in which target was in the reference list (yesno == 1) and those in which 
it wasn't (yesno == 2). 

```{r }
h <- read.table("howell_table_2_1.txt", header = TRUE, sep= ',')
# Summary of the reaction time data
h$rt <- h$rt * 10  # Make unit milliseconds
summary(h$rt)  # All data
tapply(h$rt, list(h$yesno), summary)  # By stimulus group 
```

\  

#### Histogram and Kernel Density Plot

Here is a simple histogram of the RT data. The 
distribution is obviously positively skewed (as expected with RTs), with a few 
very high values (potential outliers). 
```{r, fig.width = 6, fig.height = 5 }
# Histogram with bins of 20 ms 
hist(h$rt, breaks = seq(350, max(h$rt) + 50, by = 20), main = '',
     xlab = 'Reaction tim [ms]')
```

Some tricks needed to show a histogram with relative frequencies.
```{r, fig.width = 6, fig.height = 5 }
rel_hist <- hist(h$rt, breaks = seq(350, max(h$rt) + 50, by = 20), plot = FALSE)
rel_hist$counts <- rel_hist$counts / sum(rel_hist$counts)
plot(rel_hist, freq = TRUE, ylab = "Relative frequency", xlab = 'Reaction tim [ms]',
     main = '')
```

\ 

Here the histogram with a density plot superimposed. The y-axis now display 
'density', which means that the total area of the bars sum to 1. 
```{r, fig.width = 6, fig.height = 5 }
hist(h$rt, breaks = seq(350, max(h$rt) + 50, by = 20), freq = FALSE, main = '',
     xlab = 'Reaction tim [ms]')
# These two lines add a kernel density plot to the histogram
dens <- density(h$rt)
polygon(dens, col = rgb(0, 1, 0, 0.1))  # Forth argument of rgb() sets transparancy

```

Here density plots separately for the two groups of stimuli (In reference 
list = green; not = red).
```{r, fig.width = 6, fig.height = 5 }
hist(h$rt, breaks = seq(355, max(h$rt) + 50, by = 20), freq = FALSE, main = '',
     lty = 'blank', xlab = 'Reaction tim [ms]')
dens_yes <- density(h$rt[h$yesno == 1])
polygon(dens_yes, col = rgb(0, 1, 0, 0.2))
dens_no <- density(h$rt[h$yesno == 2])
polygon(dens_no, col = rgb(1, 0, 0, 0.2))
```

\  

#### Box plot
The box plot is our favorite. It gives an immediate feeling for how
the data is distributed, and also alerts us to potential outliers (points above or
below the whiskers).

```{r, fig.width = 6, fig.height = 5}
box_all <- boxplot(h$rt, xlab = 'All data', ylab = 'Reaction tim [ms]')
sort(box_all$out)  # Values identifed as outliers
```


Note that the grouped box-plot analysis suggests one additional outlier. Be aware 
that group differences may mask within-group outliers.
```{r, fig.width = 6, fig.height = 5 }
box_grouped <- boxplot(h$rt ~ h$yesno, 
                       xlab = 'Stimulus group (1 = On list; 2 = Not on list)',
                       ylab = 'Reaction time [ms]')
sort(box_grouped$out)
```

\  

#### Percentile plot
The percentile plot (or plot of ecdf: empirical cumulative distribution function)
is useful for evaluating the shape of the data:
```{r, fig.width = 6, fig.height = 5 }
plot(ecdf(h$rt), pch = '', verticals = TRUE, main = '', 
     xlab = 'Reaction time [ms]', ylab = 'Percentile / 100')
```

It's especially useful when comparing groups, as below where it is evident that 
the two groups of stimuli differs for all except the slowest reaction times. The 
horizontal lines indicate the 25th, 50th (median), and 75th percentile, respectively.
```{r, fig.width = 6, fig.height = 5}
plot(ecdf(h$rt[h$yesno == 1]), pch = '', verticals = TRUE, col = 'green', 
     main = '', xlab = 'Reaction time [ms]', ylab = 'Percentile / 100')
plot(ecdf(h$rt[h$yesno == 2]), pch = '', verticals = TRUE, add = TRUE, col = 'red')
lines(c(200, 1200), c(0.5, 0.5), col = 'grey')
lines(c(200, 1200), c(0.25, 0.25), col = 'grey')
lines(c(200, 1200), c(0.75, 0.75), col = 'grey')
```


\  
\  
\  
\ 


### Script2: Analysing data from a psychoacoustic experiment
Click
<a href="script2_1.R" target="_blank">here</a>
for the script file (Script2) as we left after last time.  
(Data sets:  <a href="./stat1/threshold_data.txt" target="_blank">threshold data</a>, and 
<a href="./stat1/background_data.txt" target="_blank">background data</a>. See 
<a href="./stat1/codebooks.txt" target="_blank">codebooks.txt</a>
for details on the variables).


Today we will do some descriptive statistics of the data, including plots for 
getting an idea of how the data is distributed across the three groups of listeners.
We will focus on simple between-group comparisons, and leave the age-variable for
a later seminar. 

\ 

#### Exercises
Evaluate the extent to which the listeners age is related to their performance 
on the four psychoacoustic tasks. Do this separately for the bind and the sighted 
age matched listeners. 

\  
\  



